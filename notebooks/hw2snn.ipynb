{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bb67599",
   "metadata": {},
   "source": [
    "# HW 2 - Simple Neural Networks\n",
    "\n",
    "Part 1: In this first real coding assignment, you will initially explore the operation of a single perceptron (more for historical value than for modern usefulness) and a single Sigmoid neuron to implement the \"real world\" example of going to a cheese festival.\n",
    "\n",
    "Part 2: In the second part, you will switch over to using the author's code to complete a full neural network that can recognize handwritten digits. You will train and run the network monitoring both how long it takes to train AND the test accuracy once training is complete.\n",
    "\n",
    "Part 3: In the third part, you will experiment with hyper-parameters such as the number of epochs, the batch size, and the learning rate. Again, you will monitor the training time and the test accuracy after training is complete.\n",
    "\n",
    "Part 4: In the final part, you will experiment with the network structure itself by changing the number of neurons in the hidden layer. You will again report the training time and test accuracy, but this time you will also report the evaluation time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d25619",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "class Neuron:\n",
    "  def __init__(self, w, b):\n",
    "    self.w = w\n",
    "    self.b = b\n",
    "\n",
    "  @abstractmethod\n",
    "  def output(self, x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d446292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class Perceptron(Neuron):\n",
    "  def __init__(self, w, b):\n",
    "    super().__init__(w, b)\n",
    "\n",
    "  \"\"\"\n",
    "    x: list of inputs ... must be same length as w\n",
    "    return 0 or 1 based on classic perceptron calculation weighted sum of inputs plus bias must be strictly greater than 0 to produce a 1 otherwise return a 0\n",
    "  \"\"\"\n",
    "  def output(self, x):\n",
    "    z = 0\n",
    "    for i in range(len(self.w)):\n",
    "      z = z + self.w[i]*x[i]\n",
    "    z = z + self.b\n",
    "    return 0 if z <= 0 else 1\n",
    "\n",
    "class SigmoidNeuron(Neuron):\n",
    "  def __init__(self, w, b):\n",
    "    super().__init__(w, b)\n",
    "\n",
    "  \"\"\"\n",
    "    x: list of inputs ... must be same length as w\n",
    "    return 0 or 1 based on classic perceptron calculation weighted sum of inputs plus bias must be strictly greater than 0 to produce a 1 otherwise return a 0\n",
    "  \"\"\"\n",
    "  def output(self, x):\n",
    "    z = 0\n",
    "    for i in range(len(self.w)):\n",
    "      z = z + self.w[i]*x[i]\n",
    "    z = z + self.b\n",
    "    return 1/(1+math.exp(-z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43d4a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0.9933071490757153\n",
      "0.2689414213699951\n"
     ]
    }
   ],
   "source": [
    "# PART 1a - instantiate a single Perceptron with the weights described in Chapter 1 for going to the festival. Then print out the output of calling the \"output\" function on that neuron with three combinations of inputs for the weather, girlfiend, and public transit inputs.\n",
    "p = Perceptron([6,2,2], -5)\n",
    "x = [1, 1, 1]\n",
    "a = p.output(x)\n",
    "print(a)\n",
    "x = [0,1,1]\n",
    "a = p.output(x)\n",
    "print(a)\n",
    "\n",
    "# PART 2b - repeat Part1a, but this time use a SigmoidNueron instead. Compare the output with Part 1a and explain in a comment how this part using a SigmoidNeuron could still give you the \"right\" answer about whether to go or not.\n",
    "s = SigmoidNeuron([6,2,2], -5)\n",
    "x = [1, 1, 1]\n",
    "a = s.output(x)\n",
    "print(a)\n",
    "x = [0,1,1]\n",
    "a = s.output(x)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54278848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/cosc470\n",
      "/workspaces/cosc470\n",
      "fatal: destination path 'nn' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# PART 2 - run the code below to download your author's code and then train and evaluate the network. ****Make note of the total training time and test accuracy****\n",
    "#%cd /content \n",
    "%cd \"/workspaces/cosc470/\" \n",
    "!pwd\n",
    "!git clone \"https://github.com/MichalDanielDobrzanski/DeepLearningPython\" nn\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8862b19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'nn'\n",
      "/workspaces/cosc470/nn\n",
      "50000\n",
      "10000\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01171875 0.0703125  0.0703125  0.0703125  0.4921875  0.53125\n",
      "  0.68359375 0.1015625  0.6484375  0.99609375 0.96484375 0.49609375\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1171875  0.140625   0.3671875  0.6015625\n",
      "  0.6640625  0.98828125 0.98828125 0.98828125 0.98828125 0.98828125\n",
      "  0.87890625 0.671875   0.98828125 0.9453125  0.76171875 0.25\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19140625 0.9296875  0.98828125 0.98828125 0.98828125\n",
      "  0.98828125 0.98828125 0.98828125 0.98828125 0.98828125 0.98046875\n",
      "  0.36328125 0.3203125  0.3203125  0.21875    0.15234375 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.0703125  0.85546875 0.98828125 0.98828125 0.98828125\n",
      "  0.98828125 0.98828125 0.7734375  0.7109375  0.96484375 0.94140625\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.3125     0.609375   0.41796875 0.98828125\n",
      "  0.98828125 0.80078125 0.04296875 0.         0.16796875 0.6015625\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0546875  0.00390625 0.6015625\n",
      "  0.98828125 0.3515625  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54296875\n",
      "  0.98828125 0.7421875  0.0078125  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04296875\n",
      "  0.7421875  0.98828125 0.2734375  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13671875 0.94140625 0.87890625 0.625      0.421875   0.00390625\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31640625 0.9375     0.98828125 0.98828125 0.46484375\n",
      "  0.09765625 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17578125 0.7265625  0.98828125 0.98828125\n",
      "  0.5859375  0.10546875 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0625     0.36328125 0.984375\n",
      "  0.98828125 0.73046875 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97265625\n",
      "  0.98828125 0.97265625 0.25       0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1796875  0.5078125  0.71484375 0.98828125\n",
      "  0.98828125 0.80859375 0.0078125  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15234375 0.578125   0.89453125 0.98828125 0.98828125 0.98828125\n",
      "  0.9765625  0.7109375  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09375    0.4453125\n",
      "  0.86328125 0.98828125 0.98828125 0.98828125 0.98828125 0.78515625\n",
      "  0.3046875  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08984375 0.2578125  0.83203125 0.98828125\n",
      "  0.98828125 0.98828125 0.98828125 0.7734375  0.31640625 0.0078125\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.0703125  0.66796875 0.85546875 0.98828125 0.98828125 0.98828125\n",
      "  0.98828125 0.76171875 0.3125     0.03515625 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21484375 0.671875\n",
      "  0.8828125  0.98828125 0.98828125 0.98828125 0.98828125 0.953125\n",
      "  0.51953125 0.04296875 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53125    0.98828125\n",
      "  0.98828125 0.98828125 0.828125   0.52734375 0.515625   0.0625\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# load the data into memory (training_data and test_data numpy arrays)\n",
    "%cd nn\n",
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "training_data = list(training_data)\n",
    "test_data = list(test_data)\n",
    "print(len(training_data))\n",
    "print(len(test_data))\n",
    "import numpy as np\n",
    "firstname = np.reshape(training_data[0][0], (28, 28))\n",
    "print(firstname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "812336cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 : 9064 / 10000\n",
      "Epoch 1 : 9172 / 10000\n",
      "Epoch 2 : 9296 / 10000\n",
      "Epoch 3 : 9307 / 10000\n",
      "Epoch 4 : 9379 / 10000\n",
      "Epoch 5 : 9379 / 10000\n",
      "Epoch 6 : 9401 / 10000\n",
      "Epoch 7 : 9391 / 10000\n",
      "Epoch 8 : 9400 / 10000\n",
      "Epoch 9 : 9425 / 10000\n",
      "Epoch 10 : 9435 / 10000\n",
      "Epoch 11 : 9451 / 10000\n",
      "Epoch 12 : 9445 / 10000\n",
      "Epoch 13 : 9432 / 10000\n",
      "Epoch 14 : 9435 / 10000\n",
      "Epoch 15 : 9438 / 10000\n",
      "Epoch 16 : 9457 / 10000\n",
      "Epoch 17 : 9453 / 10000\n",
      "Epoch 18 : 9449 / 10000\n",
      "Epoch 19 : 9448 / 10000\n"
     ]
    }
   ],
   "source": [
    "# default run with default hyperparameters - 20 epochs, batch size of 10, and learning rate of 3.0\n",
    "\n",
    "import importlib\n",
    "import network\n",
    "importlib.reload(network)\n",
    "net = network.Network([784, 30, 10])\n",
    "#print(training_data[800][1])\n",
    "#print(net.feedforward(training_data[800][0]))\n",
    "#print(net.biases)\n",
    "net.SGD(training_data, 20, 10, 2.5, test_data=test_data) #batch size means how many images looked at before changes are made, once all 50,000 images are run through once that is epoch 1\n",
    "\n",
    "#print(net.feedforward(training_data[800][0])) #print the output of the 800th image in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b205e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3 - experiment with the hyperparameters ... try the following combinations\n",
    "\n",
    "# three different lists of training times and three different lists on accuracys on matplotlib\n",
    "\n",
    "tt_baseline = 78.8\n",
    "acc_baseline = 94.45\n",
    "\n",
    "\n",
    "# Varying the number of epochs: 5, 10, 15, 30 (see below)\n",
    "# 5, 10, 3.0 \n",
    "# 10, 10, 3.0\n",
    "# 15, 10, 3.0\n",
    "# 30, 10, 3.0\n",
    "tt_epochs = [19.7, 38.2, 60.1, 117.1]\n",
    "acc_epochs = [93.95, 94.68, 94.84, 95.31]\n",
    "\n",
    "# Varying the batch size: 5, 20, 30\n",
    "# 20, 5, 3.0\n",
    "# 20, 20, 3.0\n",
    "# 20, 30, 3.0\n",
    "tt_batches = [81.7, 74.5, 74.8]\n",
    "acc_batches = [94.52, 94.28, 94.19]\n",
    "\n",
    "# Varying the learning rate: 2.5, 3.5, 4.0\n",
    "# 20, 10, 2.5\n",
    "# 20, 10, 3.5\n",
    "# 20, 10, 4.0\n",
    "tt_learn = []\n",
    "acc_learn = []\n",
    "\n",
    "tt = tt_epochs + tt_batches + tt_learn\n",
    "acc = acc_epochs + acc_batches + acc_learn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# After all 10 RUNS plus your original run with the defaults (20, 10, 3.0), plot your timing results and final test accuracy in a single chart using matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee4ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 4 - experiment with network structure, just try three different configurations\n",
    "# [784, 10, 10], [784, 50, 10], and [784, 100, 10]\n",
    "\n",
    "import importlib\n",
    "import network\n",
    "importlib.reload(network)\n",
    "net = network.Network([784, 30, 10])\n",
    "#print(training_data[800][1])\n",
    "#print(net.feedforward(training_data[800][0]))\n",
    "#print(net.biases)\n",
    "net.SGD(training_data, 20, 10, 3.0, test_data=test_data)\n",
    "\n",
    "# After these 3 runs, plot your training timing results, test accuracy, AND evaluation timing\n",
    "# To measure the evaluation time, manually test 100 samples from the test dataset, measure how long that takes and divide by 100 to get a per/image evaluate rate\n",
    "\n",
    "# Use Matplotlib to plot ALL THREE results (training time, test accuracy, and evaluation rate) on three different axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b07f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do your evaluation tests here after each run\n",
    "for i in range(len(test_data)):\n",
    "    net.feedforward(test_data[i][0])\n",
    "for i in range(len(training_data)):\n",
    "    net.feedforward(training_data[i][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41afdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_struct = []\n",
    "acc_struct = []\n",
    "eval_struct = []\n",
    "labels_struct = [\"[784, 10, 10]\", \"[784, 50, 10]\", \"[784, 100, 10]\", \"[784, 16, 16, 10]\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
